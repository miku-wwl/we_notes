/**/
Limit100万时加载很慢，该怎么优化？昨天一个工作5年的粉丝去面试，被问到这样一个场景问题，通过name的语句去分页查询100万页，每一页查询10条，这个查询条件如果比较慢的情况下，我们应该怎么去优化？当时没有回答出来，没人向我求助。另外我把网签的内容都打包在了Java面试指南中，里面包含了35万字面试文档，200份精选简历模板以及Java架构师学习路线图。关于这个问题呢有很多种解决方案，大家可以在回答的时候尽可能的考虑全面一点。第一种，如果ID是连续的，可以直接使用这样一个方式，这种方式其实就是先对数据做过滤，然后再limit可以有效提升查询效率。第二个通过order by加索引来解决，需要注意ID是索引链，通过索引排序以后，再勒姆同样可以减少计算次数。第三个从业务层面来考虑，限制页数，一般情况下用户去翻100页来查找数据，如果让你们老板去翻100页，估计第二天就把你开除了，我们通常会通过搜索来优化查找过程。以上呢就是我对于这个问题的回答思路，面试的时候不一定要完全陷入到面试官的逻辑里面，也可以跳出来思考。
	好的，今天的分享就到这里。Byebye。